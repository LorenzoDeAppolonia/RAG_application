{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Basics"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "888d4fa17c661a2c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lorenzodeappolonia/.local/share/virtualenvs/RAG_experimentation-cs5J6qKA/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pinecone\n",
    "\n",
    "from playground_secret_key import SECRET_KEY\n",
    "from langchain.schema import (SystemMessage, HumanMessage, AIMessage)\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = SECRET_KEY\n",
    "chat = ChatOpenAI(\n",
    "    openai_api_key = os.environ['OPENAI_API_KEY'],\n",
    "    model = 'gpt-3.5-turbo'\n",
    ")\n",
    "\n",
    "# messages = [\n",
    "#     SystemMessage(content='You are a tutor that helps highschool students.'),\n",
    "#     HumanMessage(content='Hi tutor, how are you today?'),\n",
    "#     AIMessage(content='I am great, thank you, how can I help you today?.'),\n",
    "#     HumanMessage(content='I would like you to explain to me second order derivatives')\n",
    "# ]\n",
    "# \n",
    "# # TODO : to have chat history you append both the AI response and the new prompt to the messages list\n",
    "# \n",
    "# res = chat.invoke(messages)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:49:26.576683Z",
     "start_time": "2024-03-15T10:49:25.710311Z"
    }
   },
   "id": "initial_id",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Chat history"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aab4e83a9d8fca16"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# messages.append(res)\n",
    "# prompt = HumanMessage(content='How does is this used in finding maxima and minima of a function')\n",
    "# messages.append(prompt)\n",
    "# res = chat.invoke(messages)\n",
    "# print(res.content)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T19:02:06.495502Z",
     "start_time": "2024-03-09T19:02:06.489957Z"
    }
   },
   "id": "ad47b2a3c15c6888",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "244e2553393858ad"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.38s/it]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from pathlib import Path\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "target_dir = '/Users/lorenzodeappolonia/Desktop/supervised_learning/to_do'\n",
    "documents = DirectoryLoader(path=target_dir, glob='01_*.pdf', recursive=True, show_progress=True).load_and_split()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T19:02:09.079271Z",
     "start_time": "2024-03-09T19:02:06.492254Z"
    }
   },
   "id": "bdfb7291256e0b20",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from pinecone import Pinecone \n",
    "from playground_secret_key import PINECONE_KEY\n",
    "\n",
    "os.environ['PINECONE_API_KEY'] = PINECONE_KEY\n",
    "environment = os.environ.get('PINECONE_ENVIRONMENT')\n",
    "\n",
    "pc = Pinecone()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:49:30.034746Z",
     "start_time": "2024-03-15T10:49:30.025646Z"
    }
   },
   "id": "d4f2e4490f0a85dc",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'indexes': [{'dimension': 1536,\n",
      "              'host': 'rag-xezwua8.svc.gcp-starter.pinecone.io',\n",
      "              'metric': 'cosine',\n",
      "              'name': 'rag',\n",
      "              'spec': {'pod': {'environment': 'gcp-starter',\n",
      "                               'pod_type': 'starter',\n",
      "                               'pods': 1,\n",
      "                               'replicas': 1,\n",
      "                               'shards': 1}},\n",
      "              'status': {'ready': True, 'state': 'Ready'}}]}\n"
     ]
    }
   ],
   "source": [
    "print(pc.list_indexes())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T19:02:09.613973Z",
     "start_time": "2024-03-09T19:02:09.079032Z"
    }
   },
   "id": "8225e300aae3e9b9",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# from pinecone import ServerlessSpec, PodSpec \n",
    "# import time\n",
    "# index_name = \"llama-2-rag\"\n",
    "# \n",
    "# if index_name not in pinecone.list_indexes().names():\n",
    "#     pinecone.create_index(\n",
    "#         index_name,\n",
    "#         dimension=1536,\n",
    "#         metric='cosine',\n",
    "#         spec=PodSpec(environment=\"us-west1-gcp\", pod_type=\"p1.x1\")\n",
    "# \n",
    "#     )\n",
    "# \n",
    "#     while not pinecone.describe_index(index_name).status['ready']:\n",
    "#         time.sleep(1)\n",
    "#         \n",
    "# index = pinecone.index(index_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T19:02:09.614753Z",
     "start_time": "2024-03-09T19:02:09.606626Z"
    }
   },
   "id": "c2287634a789bab1",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "62b8c233f1552468"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dimension': 256,\n",
      " 'index_fullness': 0.02794,\n",
      " 'namespaces': {'ns1': {'vector_count': 2794}},\n",
      " 'total_vector_count': 2794}\n"
     ]
    }
   ],
   "source": [
    "index = pc.Index(name='rag')\n",
    "print(index.describe_index_stats())\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:49:35.595224Z",
     "start_time": "2024-03-15T10:49:35.060274Z"
    }
   },
   "id": "11398c67c8509e78",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T19:02:10.727271Z",
     "start_time": "2024-03-09T19:02:10.717216Z"
    }
   },
   "id": "62a8c7b5444cb4dd",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embed_model = OpenAIEmbeddings(model='text-embedding-ada-002')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T19:02:10.775929Z",
     "start_time": "2024-03-09T19:02:10.721341Z"
    }
   },
   "id": "2ab90a05d0a0f1a7",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# texts = ['this is the first chunk of text',\n",
    "#          'then here is another chunk of text']\n",
    "# \n",
    "# res = embed_model.embed_documents(texts)\n",
    "# print(len(res), len(res[0]))\n",
    "# print(documents[0].page_content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T19:02:10.780377Z",
     "start_time": "2024-03-09T19:02:10.776909Z"
    }
   },
   "id": "ae554742321e9497",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': '/Users/lorenzodeappolonia/Desktop/supervised_learning/to_do/01_basics_annotated.pdf'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\\n\",\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "documents = text_splitter.split_documents(documents)\n",
    "print(documents[0].metadata)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T19:02:10.787857Z",
     "start_time": "2024-03-09T19:02:10.781609Z"
    }
   },
   "id": "120ac221ee547405",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 18\u001B[0m\n\u001B[1;32m     15\u001B[0m     j\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[1;32m     17\u001B[0m index\u001B[38;5;241m.\u001B[39mupsert(vectors \u001B[38;5;241m=\u001B[39m vectors, namespace\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mns1\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 18\u001B[0m \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m60\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# index.upsert(\u001B[39;00m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;66;03m#     vectors=[\u001B[39;00m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;66;03m#         {\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     42\u001B[0m \u001B[38;5;66;03m#     namespace= \"ns1\"\u001B[39;00m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;66;03m# )\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "batch_size = 500\n",
    "i=0\n",
    "vectors = []\n",
    "j=0\n",
    "\n",
    "for document in documents:\n",
    "    i=0\n",
    "    while i <= len(document.page_content):\n",
    "        batch = document.page_content[i:batch_size]\n",
    "        i += batch_size\n",
    "        embeds = embed_model.embed_query(batch)\n",
    "        vectors.append({'id' : f'{j}_{i}', 'values' : embeds, 'metadata': {'text': batch, 'doc_type':'PDF', 'source': document.metadata['source']}})\n",
    "    j+=1\n",
    "        \n",
    "index.upsert(vectors = vectors, namespace='ns1')\n",
    "time.sleep(60)\n",
    "\n",
    "    \n",
    "\n",
    "# index.upsert(\n",
    "#     vectors=[\n",
    "#         {\n",
    "#             \"id\": \"vec1\", \n",
    "#             \"values\": [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1], \n",
    "#             \"metadata\": {\"genre\": \"drama\"}\n",
    "#         }, {\n",
    "#             \"id\": \"vec2\", \n",
    "#             \"values\": [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], \n",
    "#             \"metadata\": {\"genre\": \"action\"}\n",
    "#         }, {\n",
    "#             \"id\": \"vec3\", \n",
    "#             \"values\": [0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3], \n",
    "#             \"metadata\": {\"genre\": \"drama\"}\n",
    "#         }, {\n",
    "#             \"id\": \"vec4\", \n",
    "#             \"values\": [0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4], \n",
    "#             \"metadata\": {\"genre\": \"action\"}\n",
    "#         }\n",
    "#     ],\n",
    "#     namespace= \"ns1\"\n",
    "# )\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T19:03:09.487040Z",
     "start_time": "2024-03-09T19:02:10.787227Z"
    }
   },
   "id": "6a8f6a20ea28e5e1",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'dimension': 1536,\n 'index_fullness': 0.00042,\n 'namespaces': {'ns1': {'vector_count': 42}},\n 'total_vector_count': 42}"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T19:03:13.040852Z",
     "start_time": "2024-03-09T19:03:12.713732Z"
    }
   },
   "id": "16b46021dccf16e1",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Michela Papandrea (SUPSI)\n",
      "\n",
      "Introduction to Supervised Learning\n",
      "\n",
      "8 / 25\n",
      "\n",
      "Data representation\n",
      "\n",
      "Despite the nature of the data, it is important to have a representation of your input data that a computer can understand commonly a dataset is representation as a table\n",
      "\n",
      "row (or entry): each data point (or sample) that we want to reason about column: each property that describes that data point (features)\n",
      "\n",
      "Michela Papandrea (SUPSI)\n",
      "\n",
      "Introduction to Supervised Learning\n",
      "\n",
      "9 / 25\n"
     ]
    }
   ],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "\n",
    "vectorstore = PineconeVectorStore.from_existing_index('rag', embed_model)\n",
    "\n",
    "query = 'Data'\n",
    "\n",
    "res = vectorstore.similarity_search(query=query, namespace='ns1', k=1)\n",
    "for el in res:\n",
    "    print(el.page_content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T19:03:17.994251Z",
     "start_time": "2024-03-09T19:03:13.220523Z"
    }
   },
   "id": "5dc858736f21d64",
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2786c38237a6b0f1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def augmented_prompt(query: str):\n",
    "    results = vectorstore.similarity_search(query=query, namespace='ns1', k=1)\n",
    "    source_knowledge = '\\n'.join([x.page_content for x in results])\n",
    "    augmented_prompt = f\"\"\"Using the context below, answer the query. \n",
    "    \n",
    "    Contexts: \n",
    "    {source_knowledge} \n",
    "    \n",
    "    Query: \n",
    "    {query}\"\"\"\n",
    "    return augmented_prompt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T19:03:18.007320Z",
     "start_time": "2024-03-09T19:03:17.996430Z"
    }
   },
   "id": "d164bc12e838e92",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the context below, answer the query. \n",
      "    \n",
      "    Contexts: \n",
      "    Michela Papandrea (SUPSI)\n",
      "\n",
      "Introduction to Supervised Learning\n",
      "\n",
      "8 / 25\n",
      "\n",
      "Data representation\n",
      "\n",
      "Despite the nature of the data, it is important to have a representation of your input data that a computer can understand commonly a dataset is representation as a table\n",
      "\n",
      "row (or entry): each data point (or sample) that we want to reason about column: each property that describes that data point (features)\n",
      "\n",
      "Michela Papandrea (SUPSI)\n",
      "\n",
      "Introduction to Supervised Learning\n",
      "\n",
      "9 / 25 \n",
      "    \n",
      "    Query: \n",
      "    Data\n"
     ]
    }
   ],
   "source": [
    "print(augmented_prompt(query))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T19:03:22.608964Z",
     "start_time": "2024-03-09T19:03:18.000442Z"
    }
   },
   "id": "e41423e3d09ef09c",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lorenzodeappolonia/.local/share/virtualenvs/RAG_experimentation-cs5J6qKA/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to Michela Papandrea, the main steps in a ML analysis are: \n",
      "1. Understand the problem we are trying to solve and if the data can solve the problem\n",
      "2. Formalize the problem\n",
      "3. Collect enough data to solve the problem\n",
      "4. Identify features and algorithms which allow right predictions\n",
      "5. Define metrics for the performance measurement\n",
      "6. Generate the predictive model and integrate the ML solution within a business product.\n"
     ]
    }
   ],
   "source": [
    "prompt = HumanMessage(\n",
    "    content=augmented_prompt('According to Michela Papandrea, what are the main steps of M.L. analysis')\n",
    ")\n",
    "messages = [prompt]\n",
    "res = chat(messages)\n",
    "\n",
    "print(res.content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T19:03:27.205975Z",
     "start_time": "2024-03-09T19:03:22.612338Z"
    }
   },
   "id": "fb85f566646bb744",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T19:03:27.206589Z",
     "start_time": "2024-03-09T19:03:27.201443Z"
    }
   },
   "id": "9ffadc30841a0fab",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pc.delete_index('rag')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T15:36:10.176243Z",
     "start_time": "2024-03-14T15:36:02.707077Z"
    }
   },
   "id": "6e218a485a404a71",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-09T19:03:09.493325Z",
     "start_time": "2024-03-09T19:03:09.493282Z"
    }
   },
   "id": "25da03ef385ac2ff",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
